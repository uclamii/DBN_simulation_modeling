{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, '../DBN_model_learning/')\n",
    "\n",
    "from pickleObjects import *\n",
    "\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.metrics import average_precision_score, precision_score, recall_score, f1_score, confusion_matrix, brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining paths\n",
    "structures_path = \"../RAUS/FullNetwork/\"\n",
    "\n",
    "model_site = \"PSJH\"\n",
    "testing_site = \"PSJH\"\n",
    "med_keyword = \"aceiarb\"\n",
    "on_medication = True\n",
    "\n",
    "models_struct_directories = [\n",
    "    model_name\n",
    "    for model_name in glob.glob(structures_path + \"*\")\n",
    "    if \"no_race\" in model_name and \"count\" not in model_name\n",
    "    and model_site in model_name\n",
    "    # and \"UCLA\" in model_name\n",
    "    # and \"PSJH\" in model_name\n",
    "    # and \"Combined\" in model_name\n",
    "]\n",
    "\n",
    "# TODO: loop model directories\n",
    "for models_struct_directory in tqdm(models_struct_directories):\n",
    "    print(models_struct_directory)\n",
    "\n",
    "    model_name = models_struct_directory.replace(structures_path, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading sensitivity analysis dictionary\n",
    "if on_medication:\n",
    "        sens_data_dict = loadObjects(\n",
    "                                \"../Data/genie_datasets/DBN_predictions/Results/sens_analysis_results/\"\n",
    "                                        + med_keyword\n",
    "                                        + \"_continuous_with_med_\"\n",
    "                                        + model_name\n",
    "                                        + \"__sens_analysis_results_applied_on_\"\n",
    "                                        + testing_site,\n",
    "                                )\n",
    "else:\n",
    "        sens_data_dict = loadObjects(\n",
    "                        \"../Data/genie_datasets/DBN_predictions/Results/sens_analysis_results/\"\n",
    "                                + med_keyword\n",
    "                                + \"_continuous_without_med_\"\n",
    "                                + model_name\n",
    "                                + \"__sens_analysis_results_applied_on_\"\n",
    "                                + testing_site,\n",
    "                        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling categories average risk for epoch 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSignVars(vars, data_dict, epoch_num):\n",
    "    \"\"\"Method to identify the statistically significanlty diefferent vars causal effect.\n",
    "    \n",
    "    Input:\n",
    "    vars: list of variables names\n",
    "    data_dict: data dictionary of statistical analysis for each epoch\n",
    "    epoch_num: the epoch number\n",
    "\n",
    "    Output:\n",
    "    sign_vars: list of statistically sign variables in terms of causal effect\n",
    "    sign_vars_categories: each variable's corresponding categories\n",
    "\n",
    "    \"\"\"\n",
    "    var_names = vars\n",
    "    sign_vars = []\n",
    "    sign_vars_categories = []\n",
    "\n",
    "    # looping each var getting categories and number of combinations for each var\n",
    "    for var_name in var_names:\n",
    "        var_indx = var_names.index(var_name)\n",
    "        categories = data_dict[\"Year \"+str(1+epoch_num)][var_names[var_indx]][\"categories\"]\n",
    "        num_combs = len(data_dict[\"Year \"+str(1+epoch_num)][var_names[var_indx]][\"combinations\"])\n",
    "\n",
    "        KS_test_signs = []\n",
    "\n",
    "        # creating list of KS test significance\n",
    "        for comb_num in range(num_combs):\n",
    "            KS_test_signs.append(data_dict[\"Year \"+str(1+epoch_num)][var_names[var_indx]][\"combinations\"][comb_num][\"KS_test_sign\"])\n",
    "\n",
    "        # at least one combination test is significant we flag the variable\n",
    "        # keep var name and categories\n",
    "        if np.any(KS_test_signs):\n",
    "            sign_vars.append(var_name)\n",
    "            sign_vars_categories.append(categories)\n",
    "    return sign_vars, sign_vars_categories\n",
    "\n",
    "def getStats(vars, data_dict, epoch_num):\n",
    "    \"\"\"Method that returns some statistics for the significant variables.\n",
    "    \n",
    "    Inputs:\n",
    "    vars: list of statistically significant variables\n",
    "    data_dict: data dictionary of statistical analysis for each epoch\n",
    "    epoch_num: the epoch number\n",
    "\n",
    "    Outputs:\n",
    "    var_avgs: list of averages for each category of each var\n",
    "    var_stds: list of stds for each category of each var \n",
    "    var_avgs_diffs: list of maximum difference in causal effect\n",
    "\n",
    "    \"\"\"\n",
    "    var_names = vars\n",
    "\n",
    "    var_avgs, var_stds, var_avgs_diffs = [], [], []\n",
    "    # looping each var getting categories and number of combinations for each var\n",
    "    for var_name in var_names:\n",
    "        var_indx = var_names.index(var_name)\n",
    "        categories = data_dict[\"Year \"+str(1+epoch_num)][var_names[var_indx]][\"categories\"]\n",
    "        num_combs = len(data_dict[\"Year \"+str(1+epoch_num)][var_names[var_indx]][\"combinations\"])\n",
    "\n",
    "        pred_avgs, pred_stds, KS_test_signs = [], [], []\n",
    "\n",
    "        # for each var's catgory generating samples average probability statistics, mean and std\n",
    "        for pred_indx in range(len(categories)):\n",
    "            pred_avgs.append(np.mean(data_dict[\"Year \"+str(1+epoch_num)][var_names[var_indx]][\"predictions_list\"][pred_indx]))\n",
    "            pred_stds.append(np.mean(data_dict[\"Year \"+str(1+epoch_num)][var_names[var_indx]][\"predictions_list\"][pred_indx]))\n",
    "\n",
    "        # storing max difference in causal effect\n",
    "        # get difference in average min from max\n",
    "        var_avgs_diffs.append(np.abs(np.min(pred_avgs)-np.max(pred_avgs)))\n",
    "        \n",
    "        var_avgs.append(pred_avgs)\n",
    "        var_stds.append(pred_stds)\n",
    "    \n",
    "    return var_avgs, var_stds, var_avgs_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = list(sens_data_dict[\"Year 1\"].keys())\n",
    "threshold_year1 = sens_data_dict['Year 1'][var_names[0]]['threshold']\n",
    "\n",
    "sign_vars_year1, sign_vars_categories_year1 = getSignVars(var_names, sens_data_dict, epoch_num=0)\n",
    "\n",
    "var_avgs_year1, var_stds_year1, var_avgs_diff_year1 = getStats(sign_vars_year1, sens_data_dict, epoch_num=0)\n",
    "\n",
    "# picking risk difference larger than 1%\n",
    "sign_vars_year1 = list(np.array(sign_vars_year1)[np.array(var_avgs_diff_year1)>0.0001])\n",
    "sign_vars_categories_year1 = list(np.array(sign_vars_categories_year1)[np.array(var_avgs_diff_year1)>0.0001])\n",
    "var_avgs_year1 = list(np.array(var_avgs_year1)[np.array(var_avgs_diff_year1)>0.0001])\n",
    "var_stds_year1 = list(np.array(var_stds_year1)[np.array(var_avgs_diff_year1)>0.0001])\n",
    "var_avgs_diff_year1 = list(np.array(var_avgs_diff_year1)[np.array(var_avgs_diff_year1)>0.0001])\n",
    "\n",
    "# picking top 3\n",
    "sign_vars_year1 = list(np.array(sign_vars_year1)[np.argsort(var_avgs_diff_year1)][::-1][:20])\n",
    "sign_vars_categories_year1 = list(np.array(sign_vars_categories_year1)[np.argsort(var_avgs_diff_year1)][::-1][:20])\n",
    "var_avgs_year1 = list(np.array(var_avgs_year1)[np.argsort(var_avgs_diff_year1)][::-1][:20])\n",
    "var_stds_year1 = list(np.array(var_stds_year1)[np.argsort(var_avgs_diff_year1)][::-1][:20])\n",
    "var_avgs_diff_year1 = list(np.array(var_avgs_diff_year1)[np.argsort(var_avgs_diff_year1)][::-1][:20])\n",
    "\n",
    "print(sign_vars_year1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_num in range(6):\n",
    "    print(\"Power: \",sens_data_dict[\"Year \"+str(1+epoch_num)][var_names[0]][\"Power\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_vars_year1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = list(sens_data_dict[\"Year 2\"].keys())\n",
    "threshold_year2 = sens_data_dict['Year 2'][var_names[0]]['threshold']\n",
    "\n",
    "sign_vars_year2, sign_vars_categories_year2 = getSignVars(var_names, sens_data_dict, epoch_num=1)\n",
    "\n",
    "var_avgs_year2, var_stds_year2, var_avgs_diff_year2 = getStats(sign_vars_year2, sens_data_dict, epoch_num=1)\n",
    "\n",
    "sign_vars_year2 = list(np.array(sign_vars_year2)[np.array(var_avgs_diff_year2)>0.0001])\n",
    "sign_vars_categories_year2 = list(np.array(sign_vars_categories_year2)[np.array(var_avgs_diff_year2)>0.0001])\n",
    "var_avgs_year2 = list(np.array(var_avgs_year2)[np.array(var_avgs_diff_year2)>0.0001])\n",
    "var_stds_year2 = list(np.array(var_stds_year2)[np.array(var_avgs_diff_year2)>0.0001])\n",
    "var_avgs_diff_year2 = list(np.array(var_avgs_diff_year2)[np.array(var_avgs_diff_year2)>0.0001])\n",
    "\n",
    "# picking top 3\n",
    "sign_vars_year2 = list(np.array(sign_vars_year2)[np.argsort(var_avgs_diff_year2)][::-1][:20])\n",
    "sign_vars_categories_year2 = list(np.array(sign_vars_categories_year2)[np.argsort(var_avgs_diff_year2)][::-1][:20])\n",
    "var_avgs_year2 = list(np.array(var_avgs_year2)[np.argsort(var_avgs_diff_year2)][::-1][:20])\n",
    "var_stds_year2 = list(np.array(var_stds_year2)[np.argsort(var_avgs_diff_year2)][::-1][:20])\n",
    "var_avgs_diff_year2 = list(np.array(var_avgs_diff_year2)[np.argsort(var_avgs_diff_year2)][::-1][:20])\n",
    "\n",
    "print(sign_vars_year2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_vars_year2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(sign_vars_year1).intersection(set(sign_vars_year2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = list(sens_data_dict[\"Year 3\"].keys())\n",
    "threshold_year3 = sens_data_dict['Year 3'][var_names[0]]['threshold']\n",
    "\n",
    "sign_vars_year3, sign_vars_categories_year3 = getSignVars(var_names, sens_data_dict, epoch_num=2)\n",
    "\n",
    "var_avgs_year3, var_stds_year3, var_avgs_diff_year3 = getStats(sign_vars_year3, sens_data_dict, epoch_num=2)\n",
    "\n",
    "sign_vars_year3 = list(np.array(sign_vars_year3)[np.array(var_avgs_diff_year3)>0.0001])\n",
    "sign_vars_categories_year3 = list(np.array(sign_vars_categories_year3)[np.array(var_avgs_diff_year3)>0.0001])\n",
    "var_avgs_year3 = list(np.array(var_avgs_year3)[np.array(var_avgs_diff_year3)>0.0001])\n",
    "var_stds_year3 = list(np.array(var_stds_year3)[np.array(var_avgs_diff_year3)>0.0001])\n",
    "var_avgs_diff_year3 = list(np.array(var_avgs_diff_year3)[np.array(var_avgs_diff_year3)>0.0001])\n",
    "\n",
    "# picking top 3\n",
    "sign_vars_year3 = list(np.array(sign_vars_year3)[np.argsort(var_avgs_diff_year3)][::-1][:20])\n",
    "sign_vars_categories_year3 = list(np.array(sign_vars_categories_year3)[np.argsort(var_avgs_diff_year3)][::-1][:20])\n",
    "var_avgs_year3 = list(np.array(var_avgs_year3)[np.argsort(var_avgs_diff_year3)][::-1][:20])\n",
    "var_stds_year3 = list(np.array(var_stds_year3)[np.argsort(var_avgs_diff_year3)][::-1][:20])\n",
    "var_avgs_diff_year3 = list(np.array(var_avgs_diff_year3)[np.argsort(var_avgs_diff_year3)][::-1][:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_vars_year3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(sign_vars_year2).intersection(set(sign_vars_year3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = list(sens_data_dict[\"Year 4\"].keys())\n",
    "threshold_year4 = sens_data_dict['Year 4'][var_names[0]]['threshold']\n",
    "\n",
    "sign_vars_year4, sign_vars_categories_year4 = getSignVars(var_names, sens_data_dict, epoch_num=3)\n",
    "\n",
    "var_avgs_year4, var_stds_year4, var_avgs_diff_year4 = getStats(sign_vars_year4, sens_data_dict, epoch_num=3)\n",
    "\n",
    "sign_vars_year4 = list(np.array(sign_vars_year4)[np.array(var_avgs_diff_year4)>0.0001])\n",
    "sign_vars_categories_year4 = list(np.array(sign_vars_categories_year4)[np.array(var_avgs_diff_year4)>0.0001])\n",
    "var_avgs_year4 = list(np.array(var_avgs_year4)[np.array(var_avgs_diff_year4)>0.0001])\n",
    "var_stds_year4 = list(np.array(var_stds_year4)[np.array(var_avgs_diff_year4)>0.0001])\n",
    "var_avgs_diff_year4 = list(np.array(var_avgs_diff_year4)[np.array(var_avgs_diff_year4)>0.0001])\n",
    "\n",
    "# picking top 4\n",
    "sign_vars_year4 = list(np.array(sign_vars_year4)[np.argsort(var_avgs_diff_year4)][::-1][:20])\n",
    "sign_vars_categories_year4 = list(np.array(sign_vars_categories_year4)[np.argsort(var_avgs_diff_year4)][::-1][:20])\n",
    "var_avgs_year4 = list(np.array(var_avgs_year4)[np.argsort(var_avgs_diff_year4)][::-1][:20])\n",
    "var_stds_year4 = list(np.array(var_stds_year4)[np.argsort(var_avgs_diff_year4)][::-1][:20])\n",
    "var_avgs_diff_year4 = list(np.array(var_avgs_diff_year4)[np.argsort(var_avgs_diff_year4)][::-1][:20])\n",
    "\n",
    "print(sign_vars_year4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_vars_year4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(sign_vars_year3).intersection(set(sign_vars_year4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = list(sens_data_dict[\"Year 5\"].keys())\n",
    "threshold_year5 = sens_data_dict['Year 5'][var_names[0]]['threshold']\n",
    "\n",
    "sign_vars_year5, sign_vars_categories_year5 = getSignVars(var_names, sens_data_dict, epoch_num=4)\n",
    "\n",
    "var_avgs_year5, var_stds_year5, var_avgs_diff_year5 = getStats(sign_vars_year5, sens_data_dict, epoch_num=4)\n",
    "\n",
    "sign_vars_year5 = list(np.array(sign_vars_year5)[np.array(var_avgs_diff_year5)>0.0001])\n",
    "sign_vars_categories_year5 = list(np.array(sign_vars_categories_year5)[np.array(var_avgs_diff_year5)>0.0001])\n",
    "var_avgs_year5 = list(np.array(var_avgs_year5)[np.array(var_avgs_diff_year5)>0.0001])\n",
    "var_stds_year5 = list(np.array(var_stds_year5)[np.array(var_avgs_diff_year5)>0.0001])\n",
    "var_avgs_diff_year5 = list(np.array(var_avgs_diff_year5)[np.array(var_avgs_diff_year5)>0.0001])\n",
    "\n",
    "# picking top 5\n",
    "sign_vars_year5 = list(np.array(sign_vars_year5)[np.argsort(var_avgs_diff_year5)][::-1][:20])\n",
    "sign_vars_categories_year5 = list(np.array(sign_vars_categories_year5)[np.argsort(var_avgs_diff_year5)][::-1][:20])\n",
    "var_avgs_year5 = list(np.array(var_avgs_year5)[np.argsort(var_avgs_diff_year5)][::-1][:20])\n",
    "var_stds_year5 = list(np.array(var_stds_year5)[np.argsort(var_avgs_diff_year5)][::-1][:20])\n",
    "var_avgs_diff_year5 = list(np.array(var_avgs_diff_year5)[np.argsort(var_avgs_diff_year5)][::-1][:20])\n",
    "\n",
    "print(sign_vars_year5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_vars_year5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(sign_vars_year4).intersection(set(sign_vars_year5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = list(sens_data_dict[\"Year 6\"].keys())\n",
    "threshold_year6 = sens_data_dict['Year 6'][var_names[0]]['threshold']\n",
    "\n",
    "sign_vars_year6, sign_vars_categories_year6 = getSignVars(var_names, sens_data_dict, epoch_num=5)\n",
    "\n",
    "var_avgs_year6, var_stds_year6, var_avgs_diff_year6 = getStats(sign_vars_year6, sens_data_dict, epoch_num=5)\n",
    "\n",
    "sign_vars_year6 = list(np.array(sign_vars_year6)[np.array(var_avgs_diff_year6)>0.0001])\n",
    "sign_vars_categories_year6 = list(np.array(sign_vars_categories_year6)[np.array(var_avgs_diff_year6)>0.0001])\n",
    "var_avgs_year6 = list(np.array(var_avgs_year6)[np.array(var_avgs_diff_year6)>0.0001])\n",
    "var_stds_year6 = list(np.array(var_stds_year6)[np.array(var_avgs_diff_year6)>0.0001])\n",
    "var_avgs_diff_year6 = list(np.array(var_avgs_diff_year6)[np.array(var_avgs_diff_year6)>0.0001])\n",
    "\n",
    "# picking top 6\n",
    "sign_vars_year6 = list(np.array(sign_vars_year6)[np.argsort(var_avgs_diff_year6)][::-1][:20])\n",
    "sign_vars_categories_year6 = list(np.array(sign_vars_categories_year6)[np.argsort(var_avgs_diff_year6)][::-1][:20])\n",
    "var_avgs_year6 = list(np.array(var_avgs_year6)[np.argsort(var_avgs_diff_year6)][::-1][:20])\n",
    "var_stds_year6 = list(np.array(var_stds_year6)[np.argsort(var_avgs_diff_year6)][::-1][:20])\n",
    "var_avgs_diff_year6 = list(np.array(var_avgs_diff_year6)[np.argsort(var_avgs_diff_year6)][::-1][:20])\n",
    "\n",
    "print(sign_vars_year6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_vars_year6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(sign_vars_year5).intersection(set(sign_vars_year6))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSortedCatsStats(var_name, categories, pred_avgs, pred_stds):\n",
    "\n",
    "    \"\"\"Method that sorts stats and cleans up genie symbols.\n",
    "    Inputs:\n",
    "    var_name: var name\n",
    "    categories: var categories\n",
    "    pred_avgs: list of each category's average prob/ causal effect\n",
    "    pred_stds: list of each category's std\n",
    "\n",
    "    Outputs:\n",
    "    sort_float_cats: list of categories converted to floats, sorted in asc order\n",
    "    sorted_pred_avgs: list of average causal effect, sorted in asc order of categories\n",
    "    sorted_pred_stds: list of std causal effect, sorted in asc order of categories \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # converting string categories to floats, to sort them\n",
    "    float_categories = []\n",
    "    for category in categories:\n",
    "        category = category.replace(\"S_\",\"\")\n",
    "\n",
    "        if \"__\" in category:\n",
    "            values = category.split(\"___\")\n",
    "        elif \"s_\" in category and \"minu\" not in category:\n",
    "            values = [\"0\", category.replace(\"s_\",\"\")]\n",
    "        elif \"le_\" in category:\n",
    "            values = [category.replace(\"le_\",\"\"), \"1000000\"]\n",
    "        else:\n",
    "            values = (category)\n",
    "\n",
    "\n",
    "        if len(values)>1 and not isinstance(values, str):  # strings have length > 0   \n",
    "            # create tuple of range and round up\n",
    "            values = tuple([np.round(float(val.replace(\"_\",\".\")),1) for val in values])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        float_categories.append(values)\n",
    "\n",
    "    # sorting list of tuples using largest number\n",
    "    # getting indces and sorted cats\n",
    "    sort_indices = [i for i, x in sorted(enumerate(float_categories), key=lambda x: x[1])]\n",
    "    sort_float_cats = [x for i, x in sorted(enumerate(float_categories), key=lambda x: x[1])]\n",
    "    # using indices generating sorted lists of avgs and stds\n",
    "    sorted_pred_avgs = [pred_avgs[sort_index] for sort_index in sort_indices]\n",
    "    sorted_pred_stds = [pred_stds[sort_index] for sort_index in sort_indices]\n",
    "    return sort_float_cats, sorted_pred_avgs, sorted_pred_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "\n",
    "def getSensPlot(var_name, sort_float_cats,sorted_pred_avgs,sorted_pred_stds,threshold):\n",
    "\n",
    "    fig = plt.figure(figsize=(30,5))\n",
    "    x = [\"> \"+str(val).replace(\"(\",\"\").replace(\")\",\"\").replace(\", 1000000.0\",\"\") if \"1000000.0\" in str(val) else\n",
    "         str(val).replace(\"(\",\"\").replace(\")\",\"\").replace(\",\",\" - \") for val in sort_float_cats]\n",
    "    y = sorted_pred_avgs\n",
    "    yerr = sorted_pred_stds\n",
    "\n",
    "    # font\n",
    "    mpl.rcParams.update({\"font.size\": 14})\n",
    "\n",
    "    plt.errorbar(x, y, yerr=yerr, label=var_name.replace(\"_\",\" \").capitalize(),fmt ='o',linestyle = '--',linewidth=3)\n",
    "    # Add value labels\n",
    "    for i in range(len(x)):\n",
    "        plt.text(x[i], y[i], f'{np.round(y[i],5)}', ha='center', va='bottom')\n",
    "    plt.axhline(y = threshold, color = 'r', linestyle = '-', alpha=0.5, linewidth=3,label=\"Threshold: \" +str(np.round(threshold,3)))\n",
    "    plt.title(var_name.replace(\"_\",\" \").capitalize())\n",
    "    plt.xlabel(\"Variable binned categories\")\n",
    "    plt.ylabel(\"Average porbability of 40% decline\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    return;\n",
    "\n",
    "\n",
    "def getSensViolinPlot(var_name, sort_float_cats,sorted_pred_avgs,sorted_pred_stds,threshold):\n",
    "\n",
    "    fig = plt.figure(figsize=(30,5))\n",
    "    x = [str(val) for val in sort_float_cats]\n",
    "    y = sorted_pred_avgs\n",
    "    yerr = sorted_pred_stds\n",
    "\n",
    "    # Create a violin plot with error bars\n",
    "    sns.violinplot(data=y)\n",
    "    i=0\n",
    "    for d,std in zip(y,yerr):\n",
    "        plt.errorbar(i, d, yerr=std, color='black', capsize=5)\n",
    "        i+=1\n",
    "\n",
    "    # plt.errorbar(x, y, yerr=yerr, label=var_name)\n",
    "    plt.axhline(y = threshold, color = 'r', linestyle = '-',label=\"Threshold\")\n",
    "    plt.title(var_name)\n",
    "    plt.xlabel(\"range or categories\")\n",
    "    plt.ylabel(\"Average porbability of 40\\% decline\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_indx,var_name in enumerate(sign_vars_year1):\n",
    "    categories = sign_vars_categories_year1[var_indx]\n",
    "    pred_avgs, pred_stds = var_avgs_year1[var_indx], var_stds_year1[var_indx]\n",
    "    sort_float_cats, sorted_pred_avgs, sorted_pred_stds = getSortedCatsStats(var_name,categories, pred_avgs, pred_stds)\n",
    "\n",
    "    getSensPlot(var_name, sort_float_cats, sorted_pred_avgs, sorted_pred_stds, threshold_year1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_indx,var_name in enumerate(sign_vars_year2):\n",
    "    categories = sign_vars_categories_year2[var_indx]\n",
    "    pred_avgs, pred_stds = var_avgs_year2[var_indx], var_stds_year2[var_indx]\n",
    "    sort_float_cats, sorted_pred_avgs, sorted_pred_stds = getSortedCatsStats(var_name,categories, pred_avgs, pred_stds)\n",
    "\n",
    "    getSensPlot(var_name, sort_float_cats, sorted_pred_avgs, sorted_pred_stds,threshold_year2)\n",
    "\n",
    "var_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_indx,var_name in enumerate(sign_vars_year3):\n",
    "    categories = sign_vars_categories_year3[var_indx]\n",
    "    pred_avgs, pred_stds = var_avgs_year3[var_indx], var_stds_year3[var_indx]\n",
    "    sort_float_cats, sorted_pred_avgs, sorted_pred_stds = getSortedCatsStats(var_name,categories, pred_avgs, pred_stds)\n",
    "\n",
    "    getSensPlot(var_name, sort_float_cats, sorted_pred_avgs, sorted_pred_stds, threshold_year3)\n",
    "\n",
    "var_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_indx,var_name in enumerate(sign_vars_year4):\n",
    "    categories = sign_vars_categories_year4[var_indx]\n",
    "    pred_avgs, pred_stds = var_avgs_year4[var_indx], var_stds_year4[var_indx]\n",
    "    sort_float_cats, sorted_pred_avgs, sorted_pred_stds = getSortedCatsStats(var_name,categories, pred_avgs, pred_stds)\n",
    "\n",
    "    getSensPlot(var_name, sort_float_cats, sorted_pred_avgs, sorted_pred_stds, threshold_year4)\n",
    "\n",
    "var_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_indx,var_name in enumerate(sign_vars_year5):\n",
    "    categories = sign_vars_categories_year5[var_indx]\n",
    "    pred_avgs, pred_stds = var_avgs_year5[var_indx], var_stds_year5[var_indx]\n",
    "    sort_float_cats, sorted_pred_avgs, sorted_pred_stds = getSortedCatsStats(var_name,categories, pred_avgs, pred_stds)\n",
    "\n",
    "    getSensPlot(var_name, sort_float_cats, sorted_pred_avgs, sorted_pred_stds, threshold_year5)\n",
    "\n",
    "var_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_indx,var_name in enumerate(sign_vars_year6):\n",
    "    categories = sign_vars_categories_year6[var_indx]\n",
    "    pred_avgs, pred_stds = var_avgs_year6[var_indx], var_stds_year6[var_indx]\n",
    "    sort_float_cats, sorted_pred_avgs, sorted_pred_stds = getSortedCatsStats(var_name,categories, pred_avgs, pred_stds)\n",
    "\n",
    "    getSensPlot(var_name, sort_float_cats, sorted_pred_avgs, sorted_pred_stds, threshold_year6)\n",
    "\n",
    "var_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1760e995f14b06106c87bf32d6451534e77cd9783514cdc2898bf5a99d0d31bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
